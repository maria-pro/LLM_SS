---
description: Retrieval-augmented generation with Ollama and transformers
---

# ðŸ¦™ Afternoon

#### <mark style="color:purple;">Slides</mark>

{% file src="../.gitbook/assets/3_2 RAG.pptx" %}

***

#### Ollama: run LLMs locally (on your computer)

<figure><img src="../.gitbook/assets/Screenshot 2024-08-18 at 7.21.17â€¯AM.png" alt="Ollama installation" width="188"><figcaption><p>Ollama</p></figcaption></figure>

**Ollama** is a platform designed to simplify the use of lLLMs **locally** on your own machine. It provides an easy-to-use interface for downloading, running, and interacting with these models **without needing extensive technical expertise or cloud resources**.

#### Why Use Ollama?

* **Privacy:** Running models locally ensures that your data never leaves your machine, which is crucial for sensitive or confidential information.
* **Control:** Local execution gives you full control over the model and its environment, allowing for customization and optimization.
* **Accessibility:** Ollama makes it easy for anyone to use advanced language models without needing extensive setup or cloud resources.

Download Ollama and install it locally

{% embed url="https://ollama.com/download" %}
